{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaptiveMD\n",
    "\n",
    "## Example 2 - Running of Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from adaptivemd import Project, Event, FunctionalEvent, Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open our `test` project by its name. If you completed the previous example this should all work out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project = Project('tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open all connections to the `MongoDB` and `Session` so we can get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where we are. These numbers will depend on whether you run this notebook for the first time or just continue again. Unless you delete your project it will accumulate models and files over time, as is our ultimate goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle for with 7 file(s) @ 0x1158bbf50>\n",
      "<ViewBundle for with 4 file(s) @ 0x1158c9090>\n",
      "<StoredBundle for with 0 file(s) @ 0x1158bbe90>\n"
     ]
    }
   ],
   "source": [
    "print project.tasks\n",
    "\n",
    "print project.trajectories\n",
    "print project.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restore our old ways to generate tasks by loading the previously used generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = project.generators['openmm']\n",
    "modeller = project.generators['pyemma']\n",
    "pdb_file = project.files['initial_pdb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we stored some files in the database and of course you can look at them again, should that be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMARK   1 CREATED WITH MDTraj 1.8.0, 2016-12-22\n",
      "CRYST1   26.063   26.063   26.063  90.00  90.00  90.00 P 1           1 \n",
      "MODEL        0\n",
      "ATOM      1  H1  ACE A   1      -1.900   1.555  26.235  1.00  0.00          H   \n",
      "ATOM      2  CH3 ACE A   1      -1.101   2.011  25.651  1.00  0.00          C   \n",
      "ATOM      3  H2  ACE A   1      -0.850   2.954  26.137  1.00  0.00          H   \n",
      "ATOM      4  H3  ACE A   1      -1.365   2.132  24.600  1.00  0.00          H   \n",
      "ATOM      5  C   ACE A   1       0.182   1.186  25.767  1.00  0.00          C   \n",
      "ATOM      6  O   ACE A   1       1.089   1.407  26.645  1.00  0.00          O   \n",
      "ATOM      7  N   ALA A   2       0.302   0.256  24.807  1.00  0.00          N   \n",
      "ATOM      8  H   ALA A   2      -0.588   0.102  24.354  1.00  0.00          H   \n",
      "ATOM      9  CA  ALA A   2       1.498  -0.651  24.567  1.00  0.00          C   \n",
      "ATOM     10  HA  ALA A   2       1.810  -0.944  25.570  1.00  0.00          H   \n",
      "ATOM     11  CB  ALA A   2       1.054  -1.959  23.852 [...]\n"
     ]
    }
   ],
   "source": [
    "print pdb_file.get_file()[:1000] + ' [...]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Run simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we talk about adaptivity, let's have a look at possibilities to generate trajectories.\n",
    "\n",
    "We assume that you successfully ran a first trajectory using a worker. Next, we talk about lot's of ways to generate new trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectories from a pdb\n",
    "\n",
    "You will do this in the beginning. Remember we already have a PDB stored from setting up the engine. if you want to start from this configuration do as before\n",
    "\n",
    "1. get the trajectory you want\n",
    "2. make a task\n",
    "3. submit the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The `Trajectory` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = next(project.traj_name)\n",
    "\n",
    "trajectory = Trajectory(\n",
    "    location=file_name,                          # this creates a new filename\n",
    "    frame=pdb_file,                              # initial frame is the PDB\n",
    "    length=100                                   # length is 100 frames\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is tedious to write there is a shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trajectory = project.new_trajectory(\n",
    "    frame=pdb_file,\n",
    "    length=100,\n",
    "    number=1          # if more then one you get a list of trajectories\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the least common multiple of all strides. You can only simulate multiples of this number. Otherwise you will not be able to extend a trajectory since the reporter will write in not equal distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.native_stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The `Task` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task_run = engine.run(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was easy, but we can do some interesting stuff. Since we know the trajectory will exist now we can also extend by some frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task_extend = engine.extend(trajectory, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only problem is to make sure the tasks are run in the correct order. This would not be a problem if the worker will run tasks in the order they are place in the queue, but that defeats the purpose of parallel runs. Therefore an extended tasks knows that is depends on the existance of the source trajectory. The worker will hence only run a trajectory, once the source exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.queue(task_run, task_extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a seconds let's see if everything went fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandbox:///{}/00000000/ 100\n",
      "sandbox:///{}/00000002/ 150\n"
     ]
    }
   ],
   "source": [
    "for t in project.trajectories:\n",
    "    print t.short, t.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandbox:///{}/00000000/ 100 1490140289.38 ['protein', 'master']\n",
      "sandbox:///{}/00000002/ 100 -1490140327.55 ['protein', 'master']\n",
      "sandbox:///{}/00000002/ 150 1490140327.55 ['protein', 'master']\n"
     ]
    }
   ],
   "source": [
    "for t in project.files:\n",
    "    if isinstance(t, Trajectory):\n",
    "        print t.short, t.length, t.created, t.types.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this works, then you should see one 100 frame trajectory from the setup (first example) and a second 150 length trajectory that we just generated by running 100 frames and extending it by another 50.\n",
    "\n",
    "If not, there might be a problem or (more likely) the tasks are not finished yet. Just try the above cell again and see if it changes to the expected output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something stupid and produce an error by using a wrong initial pdb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajectory = project.new_trajectory(engine['system_file'], 100)\n",
    "task = engine.run(trajectory)\n",
    "project.queue(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, nothing changed obviously and we expect it to fail. So let's inspect what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'fail'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It failed, well, we kind of knew that. No suprise here, but why? Let's look at the stdout and stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:52:47 [worker:3] stdout from running task\n",
      "GO...\n",
      "Reading PDB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print task.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:52:47 [worker:3] stderr from running task\n",
      "Traceback (most recent call last):\n",
      "  File \"openmmrun.py\", line 142, in <module>\n",
      "    pdb = PDBFile(args.topology_pdb)\n",
      "  File \"/Users/jan-hendrikprinz/anaconda/lib/python2.7/site-packages/simtk/openmm/app/pdbfile.py\", line 159, in __init__\n",
      "    self.positions = self._positions[0]\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print task.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, what we expect. In `openmmrun.py` the openmm executable it could not load the pdb file. \n",
    "\n",
    "> *NOTE* If your worker dies for some reason, it will not set a STDOUT or STDERR. If you think that your task should be able to execute, then you can do `task.state = 'created'` and reset it to be accessible to workers. This is NOT recommended, just to explain how this works. Of course you need a new worker anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What else\n",
    "\n",
    "If you have the trajectory object and want to just create the trajectory, you can also put this in the queue. A `Task` object is generated for you, BUT you will have no direct access to the task as in this example. Do whatever you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.queue(project.new_trajectory(pdb_file, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectories from other trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the most common case. At least in any remote kind of adaptivity you will not start always from the same position or extend. You want to pick any exisiting frame and continue from there. So, let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get a trajectory. Every bundle in the project (e.g. `.trajectories`, `.models`, `.files`, `.tasks`) acts like an enhanced set. You can iterate over all entries as we did before, and you can get one element, which usually is the first stored, but not always. For now that is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajectory = project.trajectories.one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, at least 100 frames. We pick, say, frame at index 28 (which is the 29th frame, we start counting at zero) using the way you pick an element from a python list (which is almost what a `Trajectory` represents, a list of frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame([30])\n"
     ]
    }
   ],
   "source": [
    "frame = trajectory[30]\n",
    "print frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a trajectory just use the frame as the initial frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trajectory = project.new_trajectory(frame, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = engine.run(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: TrajectoryGenerationTask(OpenMMEngine) [created]\n",
      "\n",
      "Sources\n",
      "- staging:///integrator.xml \n",
      "- sandbox:///{}/00000000/ [exists]\n",
      "- staging:///alanine.pdb \n",
      "- staging:///openmmrun.py \n",
      "- staging:///system.xml \n",
      "Targets\n",
      "- sandbox:///{}/00000007/\n",
      "Modified\n",
      "\n",
      "<pretask>\n",
      "Link('staging:///alanine.pdb' > 'worker://initial.pdb)\n",
      "Link('staging:///system.xml' > 'worker://system.xml)\n",
      "Link('staging:///integrator.xml' > 'worker://integrator.xml)\n",
      "Link('staging:///openmmrun.py' > 'worker://openmmrun.py)\n",
      "Link('sandbox:///{}/00000000/' > 'worker://source/)\n",
      "mdconvert -o worker://input.pdb -i 3 -t worker://initial.pdb worker://source/master.dcd\n",
      "Touch('worker://traj/')\n",
      "python openmmrun.py -r --report-interval 1 -p CPU --store-interval 1 --types=\"{'protein':{'stride':1,'selection':'protein','filename':'protein.dcd'},'master':{'stride':10,'selection':null,'filename':'master.dcd'}}\" -t worker://input.pdb --length 100 worker://traj/\n",
      "Move('worker://traj/' > 'sandbox:///{}/00000007/)\n",
      "<posttask>\n"
     ]
    }
   ],
   "source": [
    "print task.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.queue(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Btw, you can wait until something happens using `project.wait_until(condition)`. This is not so useful in notebooks, but in scripts it does. `condition` here is a function that evaluates to `True` or `False`. it will be tested in regular intervals and once it is `True` the function returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.wait_until(task.is_done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `Task` has a function `is_done` that you can use. It will return once a task is done. That means it either failed or succeeded or was cancelled. Basically when it is not queued anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run adaptively, _all you need to do_ is to figure out where to start new simulations from and use the methods provided to run these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Model` tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model generating task work similar to trajectories. You create the generator with options (so far, this will become more complex in the future) and then you create a `Task` from passing it a list of trajectories to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mdtraj.Topology with 2 chains, 546 residues, 1651 atoms, 1107 bonds> <mdtraj.Topology with 1 chains, 3 residues, 22 atoms, 21 bonds>\n"
     ]
    }
   ],
   "source": [
    "import pyemma\n",
    "import mdtraj as md\n",
    "from adaptivemd import Model\n",
    "\n",
    "pdb = md.load(\"../files/alanine/alanine.pdb\")\n",
    "topology = pdb.topology\n",
    "\n",
    "selection = 'protein'\n",
    "\n",
    "if selection:\n",
    "    topology = topology.subset(topology.select(selection_string=selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topology.subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = modeller.task_run_msm_files(list(project.trajectories), outtype='protein')\n",
    "project.queue(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clustering': {'dtrajs': [array([3, 0, 0, 3, 3, 4, 4, 3, 4, 3, 0], dtype=int32),\n",
       "   array([3, 0, 0, 3, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 3], dtype=int32),\n",
       "   array([3, 0, 0, 3, 3, 2, 3, 0, 0, 0, 0], dtype=int32),\n",
       "   array([3, 3, 1, 1, 3, 4, 3, 0, 2, 2, 2], dtype=int32),\n",
       "   array([3, 3, 4, 1, 4, 4, 4, 2, 2, 2, 2], dtype=int32)],\n",
       "  'k': 5},\n",
       " 'input': {'dimension': 2,\n",
       "  'frames': 60,\n",
       "  'lengths': array([11, 16, 11, 11, 11]),\n",
       "  'n_trajectories': 5,\n",
       "  'pdb': 'input.pdb',\n",
       "  'trajectories': [Trajectory('alanine.pdb' >> [0..100]),\n",
       "   Trajectory('alanine.pdb' >> [0..150]),\n",
       "   Trajectory('alanine.pdb' >> [0..100]),\n",
       "   Trajectory(Frame([30]) >> [0..100]),\n",
       "   Trajectory(Frame([30]) >> [0..100])]},\n",
       " 'msm': {'C': array([[ 2.,  0.,  2.,  6.,  0.],\n",
       "         [ 0.,  0.,  0.,  1.,  2.],\n",
       "         [ 3.,  0.,  8.,  1.,  0.],\n",
       "         [ 4.,  3.,  4.,  3.,  3.],\n",
       "         [ 2.,  0.,  2.,  1.,  3.]]),\n",
       "  'P': array([[ 0.2       ,  0.        ,  0.3112346 ,  0.39567712,  0.09308828],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.63506525,  0.36493475],\n",
       "         [ 0.1573045 ,  0.        ,  0.66666666,  0.11843112,  0.05759772],\n",
       "         [ 0.35548405,  0.12322378,  0.21051921,  0.17647059,  0.13430237],\n",
       "         [ 0.13363965,  0.11314947,  0.16360342,  0.21460746,  0.375     ]]),\n",
       "  'lagtime': 2},\n",
       " 'tica': {'dimension': 2, 'lagtime': 2}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.models.last.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<adaptivemd.model.Model object at 0x10a956e90>\n"
     ]
    }
   ],
   "source": [
    "for m in project.models:\n",
    "    print m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we generated one model. The `Model` objects contain (in the base version) only a `.data` attribute which is a dictionary of information about the generated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clustering', 'input', 'msm', 'tica']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = project.models.last\n",
    "model.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.81176471  0.          0.0605401   0.0795361   0.04815909]\n",
      " [ 0.          0.89473683  0.          0.09372983  0.01153333]\n",
      " [ 0.10295456  0.          0.83720931  0.          0.05983614]\n",
      " [ 0.01137093  0.02236942  0.          0.96330274  0.00295691]\n",
      " [ 0.03150385  0.01259462  0.02301687  0.01352981  0.91935484]]\n"
     ]
    }
   ],
   "source": [
    "print model.data['msm']['P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick frames automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing that is implemented is a function that can utilize models to decide which frames are better to start from. The simplest one will use the counts per state, take the inverse and use this as a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Frame([74]), Frame([69]), Frame([93]), Frame([97])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.find_ml_next_frame(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can pick states according to the newest (last) model. (This will be moved to the Brain). And since we want trajectories with these frames as starting points there is also a function for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trajectory(Frame([95]) >> [0..100]),\n",
       " Trajectory(Frame([31]) >> [0..100]),\n",
       " Trajectory(Frame([89]) >> [0..100]),\n",
       " Trajectory(Frame([72]) >> [0..100])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories = project.new_ml_trajectory(length=100, number=4)\n",
    "trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit these before we finish this notebook with a quick discussion of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.queue(trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worker are the instances that execute tasks for you. If you did not stop the worker it will still be running and you can check its state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from adaptivemd import DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DT is a little helper to convert time stamps into something readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[running:12:53:36] Stevie.fritz.box:/Users/jan-hendrikprinz/Studium/git/adaptivemd\n"
     ]
    }
   ],
   "source": [
    "project.trigger()\n",
    "for w in project.workers:\n",
    "    if w.state == 'running':\n",
    "        print '[%s:%s] %s:%s' % (w.state, DT(w.seen).time, w.hostname, w.cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the worker is running, was last reporting its heartbeat at ... and has a hostname and current working directory (where it was executed from). The generators specify which tasks from some generators are executed. If it is `None` then the worker runs all tasks it finds. You can use this to run specific workers for models and some for trajectory generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also control it remotely by sending it a command. `shutdown` will shut it down for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# project.workers.last.command = 'shutdown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards you need to restart you worker to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
